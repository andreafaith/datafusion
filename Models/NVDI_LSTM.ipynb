{"cells":[{"cell_type":"markdown","metadata":{"id":"9dEjG0hFECYD"},"source":["### The provided code segment consists of a series of import statements for essential libraries used in deep learning and image processing. It includes TensorFlow, PIL, glob, and pandas. Additionally, there are commented-out lines of code to mount the Google Drive to access stored files."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"It07Us9t6H1R"},"outputs":[],"source":["# Import the necessary libraries\n","import os\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\n","from PIL import Image\n","from glob import glob\n","import pandas as pd\n","\n","# # Mount your Google Drive\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ezTkDhk0ECYH"},"source":["### This code segment processes a collection of JPG image files by flattening them into one-dimensional arrays and organizing them into a Pandas DataFrame. It outlines the setup for training an LSTM neural network model on this data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R0nmRUGDNygT","outputId":"5c772ccc-3f55-4814-e3ab-9e7f93478af1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/10\n","615/615 [==============================] - 26s 39ms/step - loss: 0.0026\n","Epoch 2/10\n","615/615 [==============================] - 24s 38ms/step - loss: 7.9433e-06\n","Epoch 3/10\n","615/615 [==============================] - 23s 38ms/step - loss: 3.2250e-06\n","Epoch 4/10\n","615/615 [==============================] - 23s 37ms/step - loss: 2.5930e-06\n","Epoch 5/10\n","615/615 [==============================] - 24s 38ms/step - loss: 4.8411e-06\n","Epoch 6/10\n","615/615 [==============================] - 23s 38ms/step - loss: 4.9191e-06\n","Epoch 7/10\n","615/615 [==============================] - 23s 38ms/step - loss: 6.1925e-06\n","Epoch 8/10\n","615/615 [==============================] - 25s 40ms/step - loss: 8.2359e-06\n","Epoch 9/10\n","615/615 [==============================] - 25s 41ms/step - loss: 8.3202e-06\n","Epoch 10/10\n","615/615 [==============================] - 25s 40ms/step - loss: 8.1672e-06\n"]}],"source":["import pandas as pd\n","# from google.colab import drive\n","import os\n","import numpy as np\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","\n","# Set the path to the folder containing the jpg files.\n","folder_path = 'sentinel_2_l1c_toImages'\n","\n","# Select all the jpg files in the folder.\n","jpg_files = []\n","for file in os.listdir(folder_path):\n","    if file.endswith(\".jpg\"):\n","        jpg_files.append(os.path.join(folder_path, file))\n","\n","# Flatten the jpg files.\n","flattened_jpg_files = []\n","for jpg_file in jpg_files:\n","    image = Image.open(jpg_file)\n","    image_array = np.array(image)\n","    flattened_jpg_files.append(image_array.flatten())\n","\n","# Reshape the flattened jpg files to have two dimensions.\n","flattened_jpg_files = np.reshape(flattened_jpg_files, (len(flattened_jpg_files), -1))\n","\n","# Create a Pandas DataFrame from the flattened jpg files.\n","df = pd.DataFrame(flattened_jpg_files)\n","df = np.transpose(df)\n","df = np.expand_dims(df, axis=2)\n","\n","# Set the path to the folder containing the test jpg files.\n","test_directory = 'test_images'\n","\n","# Split the DataFrame into a training set and a test set.\n","training_set = df[:int(0.8 * len(df))]\n","test_set = df[int(0.8 * len(df)):]\n","\n","# # Transpose the training set.\n","# training_set = np.transpose(training_set)\n","# test_set = np.transpose(test_set)\n","\n","# # Reshape the transposed training set to have three dimensions.\n","# training_set = np.expand_dims(training_set, axis=2)\n","# test_set = np.expand_dims(test_set, axis=2)\n","\n","# Train an LSTM model on the training set.\n","model = Sequential()\n","model.add(LSTM(128, input_shape=(training_set.shape[1], training_set.shape[2])))\n","model.add(Dense(1))\n","model.compile(loss='mse', optimizer='adam')\n","history = model.fit(training_set, np.zeros(training_set.shape[0]), epochs=10, batch_size= 1024)\n"]},{"cell_type":"markdown","metadata":{"id":"KyH7oAJPECYI"},"source":["### This code snippet evaluates the LSTM neural network model on a test dataset and prints the test loss. This serves as an indicator of the model's performance on unseen data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eSuveTn-ECYI","outputId":"13db1074-8852-4717-94ac-883bbd063bae"},"outputs":[{"name":"stdout","output_type":"stream","text":["4916/4916 [==============================] - 61s 12ms/step - loss: 5.2572e-07\n","Test loss: 5.257240331957291e-07\n"]}],"source":["# Evaluate the LSTM model on the test set.\n","test_loss = model.evaluate(test_set, np.zeros(test_set.shape[0]))\n","print(\"Test loss:\", test_loss)"]},{"cell_type":"markdown","metadata":{"id":"NKlhV6ymECYJ"},"source":["### In this code, the pre-trained model, 'NVDI_LSTM.h5' is loaded. A random image with a specific shape (1, 97, 1) is created to match the expected input shape of the model. The model then makes a prediction on this tensor, and the resulting prediction is printed to the console."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_jDTK8HRECYJ","outputId":"7bdb6f8a-26f4-43fc-b79e-6ba24735107c"},"outputs":[{"name":"stdout","output_type":"stream","text":["1/1 [==============================] - 0s 362ms/step\n","[[-0.00325889]]\n"]}],"source":["import numpy as np\n","from tensorflow.keras.models import load_model\n","\n","# Load the model.\n","model = load_model('NVDI_LSTM.h5')\n","\n","# Create a preprocessed image tensor.\n","image_tensor = np.random.rand(1, 97, 1)  # Adjust the shape to match the expected input shape.\n","\n","# Make a prediction on the tensor.\n","prediction = model.predict(image_tensor)\n","\n","# Print the prediction.\n","print(prediction)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}